# 中间件速成 Ch27 Kafka 高性能消息队列

这里学习的 Kafka 与之前学习的 RabbitMQ 的区别是，Kafka 其实更注重的是流式数据，高吞吐的性能处理，而 RabbitMQ 性能比 Kafka 差，但提供了更多的特性。Kafka 适用于日志收集与处理等场景，一般只有数据量足够大才需要用到它。

注意，Kafka 是一种持久化的订阅-发布模式，可以用于存储数据，且在消息转发后不会丢弃。

## 基本概念

1. Broker（代理节点）
- 这是 Kafka 集群中的服务器节点
- 每个 broker 负责存储数据并处理客户端请求
- 多个 broker 组成一个 Kafka 集群

2. Controller（控制器）
- 是一个特殊的 broker，由集群选举产生
- 负责管理集群状态，如分区分配、leader 选举等
- 一个集群只有一个 controller

3. Topic（主题）
- 是消息的逻辑分类
- 相当于一个消息队列或频道
- 比如可以有"订单"、"支付"等不同的 topic

4. Partition（分区）
- 每个 topic 可以分成多个 partition
- partition 是数据存储和复制的基本单位
- 不同 partition 可以分布在不同 broker 上，实现负载均衡

5. Message/Record（消息/记录）
- 这是 Kafka 中最基本的数据单元
- 包含 key、value、timestamp 等信息
- 发送到 topic 中的每条数据就是一条 message

它们之间的关系是：

```
Kafka集群
  ├── 多个 Broker (其中一个是 Controller)
  └── 多个 Topic
       └── 多个 Partition
            └── 多条 Message
```

假设有一个电商系统，可能会有：

- "订单" topic：存储订单相关消息
- "支付" topic：存储支付相关消息

每个 topic 可能分成 3 个 partition，分布在不同 broker 上，提高并行处理能力。

下面介绍一下 kafka 的架构。

1. 基本架构
```
生产者 -> Kafka集群 -> 消费者
            ↓
        ZooKeeper/KRaft
```

2. 核心组件和职责：

Producer（生产者）

- 负责发送消息到 Kafka 集群
- 可以指定分区策略（轮询、hash等）
- 支持同步或异步发送

Consumer（消费者）

- 从 Kafka 集群读取消息
- 可以组成 Consumer Group 进行消费
- 每个分区只能被同一组内的一个消费者消费

Consumer Group（消费者组）

- 多个消费者组成一组
- 实现消息的并行消费
- 提供故障转移能力

3. 高可用机制：

副本机制，使用一主多备机制。

- 每个分区有多个副本（replica）
- 一个 leader 副本和多个 follower 副本
- follower 从 leader 同步数据
- 当 leader 故障时，从 follower 中选举新的 leader

4. 示例架构：

```
Producer层
    ↓
Broker集群
  ├── Broker1 (Controller)
  │   └── Partition1-Leader
  │   └── Partition2-Follower
  ├── Broker2
  │   └── Partition1-Follower
  │   └── Partition2-Leader
  ├── Broker3
  │   └── Partition1-Follower
  │   └── Partition2-Follower
    ↓
Consumer Group层
```

5. 关键特性：

- 分区提供并行处理能力
- 副本提供高可用性
- Consumer Group 提供扩展性
- Controller 提供集中式管理
- 支持水平扩展

这种架构设计使 Kafka：

- 具有高吞吐量
- 可靠性强
- 容错性好
- 易于扩展

## 启动 Kafka

注意，在以前版本，Kafka 需要搭配 Zookeeper。但是现在 Kraft 是更推荐的机制。

这里直接使用 Docker 启动一个 Kafka 集群。

```bash
docker pull apache/kafka-native:3.9.0
docker run -p 9092:9092 apache/kafka-native:3.9.0
```

使用 native 版本的镜像性能更好，不过在我们测试过程中这不重要。

Kafka 的配置文件在 Container 的 `/opt/kafka/config` 中，也可以在启动 Container 时使用环境变量配置。

上面这样只启动了一个容器，以下是一个集群的 Docker Compose，在生产环境中请使用 k8s 或 ansible 搭建集群。

```yaml
version: '3.8'
services:
  kafka1:
    image: confluentinc/cp-kafka:latest
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_KRAFT_MODE: "true"                # 启用 Kraft 模式
      KAFKA_NODE_ID: 1
      CLUSTER_ID: "D33X72A2-F71B-4921-846F-C9F9D3EB562D"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka1:9092"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - ./kafka1/data:/var/lib/kafka/data

  kafka2:
    image: confluentinc/cp-kafka:latest
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9093:9092"
    environment:
      KAFKA_KRAFT_MODE: "true"
      KAFKA_NODE_ID: 2
      CLUSTER_ID: "D33X72A2-F71B-4921-846F-C9F9D3EB562D"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka2:9092"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - ./kafka2/data:/var/lib/kafka/data

  kafka3:
    image: confluentinc/cp-kafka:latest
    hostname: kafka3
    container_name: kafka3
    ports:
      - "9094:9092"
    environment:
      KAFKA_KRAFT_MODE: "true"
      KAFKA_NODE_ID: 3
      CLUSTER_ID: "D33X72A2-F71B-4921-846F-C9F9D3EB562D"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka3:9092"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - ./kafka3/data:/var/lib/kafka/data
```

现在我们解释一下这个 Compose 文件。我们使用了 confluentinc 提供的 Kafka，相比基础的 Kafka 提供了更多的功能。

- KAFKA_KRAFT_MODE 开启后 Kafka 集群是自治的，不需要额外的 Zookeeper 集群
- KAFKA_NODE_ID 即节点 ID
- CLUSTER_ID 即集群 ID，通常随机生成一个 UUID 即可。
- KAFKA_PROCESS_ROLES 是当前节点在 Kafka 集群中扮演的角色，在 Kraft 模式下，KAFKA_PROCESS_ROLES 参数定义了节点的角色，broker 负责存储和处理消息，执行生产者和消费者的请求。	controller 负责管理集群的元数据、分区分配、状态监控等任务。broker,controller 表示该节点既是 broker 又是 controller，适用于 Kraft 模式下的小型集群。
- KAFKA_LISTENERS 配置 Kafka 服务监听的协议和端口，PLAINTEXT://kafka1:9092,CONTROLLER://kafka1:9093 PLAINTEXT 是客户端生产/消费消息的协议。CONTROLLER 是控制器之间通信的协议，集群中的每个 controller 都需要监听该协议。
- KAFKA_ADVERTISED_LISTENERS 配置 Kafka 节点向客户端（如生产者和消费者）公开的地址和端口。例如：PLAINTEXT://localhost:9092 客户端连接 Kafka 时会根据此参数找到正确的 broker。
- KAFKA_CONTROLLER_QUORUM_VOTERS 定义 controller 的投票者列表，格式为 nodeId@address:port。例如：1@kafka1:9093，2@kafka2:9093，3@kafka3:9093 这意味着节点 kafka1、kafka2 和 kafka3 都是 controller，且它们之间通过 CONTROLLER 协议通信。当集群中主机不可达，就会触发选举重新选主机。
- KAFKA_LOG_DIRS 定义 Kafka 用于存储日志数据的目录。在此示例中为 `/var/lib/kafka/data`

## 操纵 Kafka

这里我们使用 NodeJS 操纵 Kafka 集群。当然，单机 NodeJS 处理可能性能不够，但是在微服务场景下，因为服务可以自由伸缩，因此单机的性能反而不是很重要了。

写代码前，先进入一个容器，用容器内的脚本创建 topic。

```bash
docker exec -it kafka1 bash
```

然后用命令，

```bash
kafka-topics --create \
  --topic test-topic \
  --partitions 3 \
  --replication-factor 2 \
  --bootstrap-server kafka1:9092
```

如果配置全部正确，会显示 `Created topic orders`。

然后我们写 consumer 和 producer。需要安装 kafkajs 库。

